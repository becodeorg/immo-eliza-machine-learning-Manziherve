{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abc2e5b",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d543747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a12e1",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175841d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Kangaroo_main.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b5b61",
   "metadata": {},
   "source": [
    "Drop irrelevant columns for price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1994bbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = data.drop(columns=[\n",
    "    \"url\",\n",
    "    \"id\",\n",
    "    \"hasBalcony\",\n",
    "    \"floorCount\",\n",
    "    \"diningRoomSurface\",\n",
    "    \"monthlyCost\",\n",
    "    \"hasGarden\",\n",
    "    \"hasTerrace\",\n",
    "    \"accessibleDisabledPeople\",\n",
    "    \"Unnamed: 0\",\n",
    "    \"terraceOrientation\",\n",
    "    \"hasDressingRoom\",\n",
    "    \"hasDiningRoom\",\n",
    "    \"streetFacadeWidth\",\n",
    "    \"hasHeatPump\",\n",
    "    \"hasPhotovoltaicPanels\",\n",
    "    \"hasThermicPanels\",\n",
    "    \"hasLivingRoom\",\n",
    "    \"gardenOrientation\",\n",
    "    \"parkingCountOutdoor\",\n",
    "    \"hasArmoredDoor\",\n",
    "    \"hasVisiophone\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bac476",
   "metadata": {},
   "source": [
    "Drop Big Values (Outliers) and fillna some of them with the median values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97764ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\3379475542.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  drop_out[\"bedroomCount\"].fillna(median_bedrooms, inplace=True)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\3379475542.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  drop_out[\"bathroomCount\"].fillna(median_bathrooms, inplace=True)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\3379475542.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  drop_out[\"habitableSurface\"].fillna(median_hS, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "drop_out = drop_cols\n",
    "drop_out.loc[drop_out[\"bedroomCount\"] >= 100, \"bedroomCount\"] = np.nan\n",
    "median_bedrooms = drop_out[\"bedroomCount\"].median()\n",
    "drop_out[\"bedroomCount\"].fillna(median_bedrooms, inplace=True)\n",
    "# ..............................................................\n",
    "drop_out.loc[drop_out[\"bathroomCount\"] >= 100, \"bathroomCount\"] = np.nan\n",
    "median_bathrooms = drop_out[\"bathroomCount\"].median()\n",
    "drop_out[\"bathroomCount\"].fillna(median_bathrooms, inplace=True)\n",
    "#...............................................................\n",
    "drop_out.loc[drop_out[\"habitableSurface\"] >= 600,\"habitableSurface\"] = np.nan\n",
    "median_hS = drop_out[\"habitableSurface\"].median()\n",
    "drop_out[\"habitableSurface\"].fillna(median_hS, inplace=True)\n",
    "#...............................................................\n",
    "drop_out.loc[drop_out[\"toiletCount\"] >= 25, \"toiletCount\"] = 1\n",
    "drop_out.loc[drop_out[\"landSurface\"] >= 1000, \"landSurface\"] = 0\n",
    "drop_out.loc[drop_out[\"gardenSurface\"] >= 500, \"gardenSurface\"] = 0\n",
    "drop_out.loc[drop_out[\"terraceSurface\"] >= 250, \"terraceSurface\"] = 0\n",
    "drop_out.loc[drop_out[\"parkingCountIndoor\"] >= 10, \"parkingCountIndoor\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae5cdb3",
   "metadata": {},
   "source": [
    "Fill the missing values in these columns (\"gardenSurface, terraceSurface) with 0 \n",
    "    And fill the missing values in (habitableSurface, bathroomCount and bedroomCount) with their median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81a6e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"gardenSurface\"] = drop_cols[\"gardenSurface\"].fillna(0)    # Replace NaNs with 0\n",
    "drop_cols[\"terraceSurface\"] = drop_cols[\"terraceSurface\"].fillna(0)   # Replace NaNs with 0 # Replace NaNs with median value\n",
    "drop_cols[\"bathroomCount\"] = drop_cols[\"bathroomCount\"].fillna(drop_cols[\"bathroomCount\"].mode()) # Replace NaNs with median value\n",
    "drop_cols[\"bedroomCount\"] = drop_cols[\"bedroomCount\"].fillna(drop_cols[\"bedroomCount\"].mode()) # Replace NaNs with median value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6d56fa",
   "metadata": {},
   "source": [
    "Drop Nan Values in \"price\" and \"habitableSurface\" columns                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7c23b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols.dropna(subset=[\"price\"], inplace=True)\n",
    "drop_cols.dropna(subset=[\"habitableSurface\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521c698",
   "metadata": {},
   "source": [
    "Merge type and subtype without making doubles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d152ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"type_subtype\"] = (drop_cols[\"type\"].str.upper() + \" \" + drop_cols[\"subtype\"].str.upper()) #concatenate type and subtype into a new column called type_subtype\n",
    "drop_cols[\"type_subtype\"] = drop_cols[\"type_subtype\"].apply(lambda x: \" \" .join(sorted(set(x.split())))) # delete duplicates in the type_subtype column\n",
    "drop_cols.drop(columns=[\"type\"], inplace=True)\n",
    "drop_cols.drop(columns=[\"subtype\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04eb74f",
   "metadata": {},
   "source": [
    "Divide \"type_subtype\" in two columns \"apartment_map_score\" and \"house_map_score\" and map them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61bb6b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to assign a score to each apartment type based on its category\n",
    "apartment_map_score = {\n",
    "    'APARTMENT KOT': 0,\n",
    "    'APARTMENT FLAT_STUDIO': 1,\n",
    "    'APARTMENT GROUND_FLOOR': 2,\n",
    "    'APARTMENT': 3,\n",
    "    'APARTMENT DUPLEX': 4,\n",
    "    'APARTMENT TRIPLEX': 5,\n",
    "    'APARTMENT LOFT': 6,\n",
    "    'APARTMENT SERVICE_FLAT': 7,\n",
    "    'APARTMENT PENTHOUSE': 8\n",
    "}\n",
    "# Dictionary to assign a score to each house type based on its category\n",
    "house_map_score = {\n",
    "    'HOUSE': 0,\n",
    "    'HOUSE MIXED_USE_BUILDING': 1,\n",
    "    'COUNTRY_COTTAGE HOUSE': 2,\n",
    "    'CHALET HOUSE': 3,\n",
    "    'BUNGALOW HOUSE': 4,\n",
    "    'HOUSE TOWN_HOUSE': 5,\n",
    "    'FARMHOUSE HOUSE': 6,\n",
    "    'HOUSE OTHER_PROPERTY': 7,\n",
    "    'HOUSE VILLA': 8,\n",
    "    'HOUSE PAVILION': 9,\n",
    "    'HOUSE MANOR_HOUSE': 10,\n",
    "    'EXCEPTIONAL_PROPERTY HOUSE': 11,\n",
    "    'CASTLE HOUSE': 12\n",
    "}\n",
    "drop_cols['apartment_map_score'] = drop_cols['type_subtype'].map(apartment_map_score)\n",
    "drop_cols['house_map_score'] = drop_cols['type_subtype'].map(house_map_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd17abcd",
   "metadata": {},
   "source": [
    "Deal with \"locality\" doubles and orthographic faults ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acf0a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Convert both the 'locality' and 'province' columns to uppercase for uniform comparison\n",
    "drop_cols[\"locality\"] = drop_cols[\"locality\"].str.upper()\n",
    "drop_cols[\"province\"] = drop_cols[\"province\"].str.upper()\n",
    "\n",
    "# Dictionary to store the matched pairs\n",
    "standard_map = {}\n",
    "\n",
    "# Function to find a match from the known standards\n",
    "def find_match(name, standards, threshold=80):\n",
    "    if not standards:\n",
    "        return None  # No standards to compare to, return None\n",
    "\n",
    "    # Use rapidfuzz to find the closest match to the 'name' from the 'standards' list using the token_sort_ratio scoring method\n",
    "    result = process.extractOne(name, standards, scorer=fuzz.token_sort_ratio)\n",
    "    \n",
    "    if result is None:\n",
    "        return None  # No match found, return None\n",
    "    \n",
    "    match, score, _ = result\n",
    "    return match if score >= threshold else None  # Return match if score is greater than the threshold, else None\n",
    "\n",
    "# List to store all standardized names encountered so far\n",
    "standards = []\n",
    "\n",
    "# Main loop to iterate through the 'locality' column\n",
    "for name in drop_cols['locality']:\n",
    "    match = find_match(name, standards)  # Try to find a match for the current locality\n",
    "    if match:\n",
    "        standard_map[name] = match  # If a match is found, store it in the dictionary\n",
    "    else:\n",
    "        standard_map[name] = name  # If no match is found, keep the name as it is\n",
    "        standards.append(name)  # Add the name to the list of standards\n",
    "\n",
    "# Create a new column with normalized locality names\n",
    "drop_cols['locality_normalized'] = drop_cols['locality'].map(standard_map)\n",
    "\n",
    "# Identify rows where the 'locality' has been changed to its normalized form\n",
    "modifications = drop_cols[drop_cols['locality'] != drop_cols['locality_normalized']]\n",
    "\n",
    "# Now, normalize the locality by concatenating the 'postCode' and 'locality' in uppercase\n",
    "drop_cols[\"locality_normalized\"] = (\n",
    "    drop_cols[\"postCode\"].astype(str).str.upper() + \" - \" + drop_cols[\"locality\"].astype(str).str.upper()\n",
    ")\n",
    "\n",
    "# Drop the original 'locality' and 'postCode' columns as they are no longer needed\n",
    "drop_cols.drop(columns=[\"locality\"], inplace=True)\n",
    "drop_cols.drop(columns=[\"postCode\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b4de2",
   "metadata": {},
   "source": [
    "Merge \"postCode\" with \"province\" and renaming the column from \"postCode\" to \"postCode-province\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7f0eaf",
   "metadata": {},
   "source": [
    "Fill \"kitchenType\" missing values with \"INSTALLED\" if there is a value in \"kitchenSurface\" and Drop rows with missing values in both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ccd43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols.loc[drop_cols[\"kitchenSurface\"].notna() & (drop_cols[\"kitchenSurface\"] != \"\") & (drop_cols[\"kitchenType\"].isna()), \"kitchenType\"] = \"INSTALLED\"\n",
    "drop_cols = drop_cols[~(drop_cols[\"kitchenType\"].isna() & drop_cols[\"kitchenSurface\"].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d53e23",
   "metadata": {},
   "source": [
    "Mapping of \"floodZoneType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "894d326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2513258033.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"floodZoneMapping\"] = drop_cols[\"floodZoneType\"].map(floodZoneMapping)\n"
     ]
    }
   ],
   "source": [
    "floodZoneMapping = {\n",
    "    \"NON_FLOOD_ZONE\": 0,\n",
    "    \"POSSIBLE_N_CIRCUMSCRIBED_WATERSIDE_ZONE\": 1,\n",
    "    \"CIRCUMSCRIBED_WATERSIDE_ZONE\": 2,\n",
    "    \"POSSIBLE_N_CIRCUMSCRIBED_FLOOD_ZONE\": 3,\n",
    "    \"POSSIBLE_FLOOD_ZONE\": 4,\n",
    "    \"CIRCUMSCRIBED_FLOOD_ZONE\": 5,\n",
    "    \"RECOGNIZED_FLOOD_ZONE\": 6,\n",
    "    \"RECOGNIZED_N_CIRCUMSCRIBED_WATERSIDE_FLOOD_ZONE\": 7,\n",
    "    \"RECOGNIZED_N_CIRCUMSCRIBED_FLOOD_ZONE\": 8\n",
    "}\n",
    "drop_cols[\"floodZoneMapping\"] = drop_cols[\"floodZoneType\"].map(floodZoneMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f504949e",
   "metadata": {},
   "source": [
    "Mapping of \"epcScore\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee0fb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2430905767.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"epcScoreMapping\"] = drop_cols[\"epcScore\"].map(epcScoreMapping)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2430905767.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols.fillna(0, inplace=True)  # Fill NaN values with 0 for epcScoreMapping and floodZoneMapping columns\n"
     ]
    }
   ],
   "source": [
    "epcScoreMapping = {\n",
    "    \"A++\": 1,\n",
    "    \"A+\": 2,\n",
    "    \"A\": 3,\n",
    "    \"B\": 4,\n",
    "    \"C\": 5,\n",
    "    \"D\": 6,\n",
    "    \"E\": 7,\n",
    "    \"F\": 8,\n",
    "    \"G\": 9\n",
    "}\n",
    "drop_cols[\"epcScoreMapping\"] = drop_cols[\"epcScore\"].map(epcScoreMapping)\n",
    "drop_cols.fillna(0, inplace=True)  # Fill NaN values with 0 for epcScoreMapping and floodZoneMapping columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40878e31",
   "metadata": {},
   "source": [
    "Mapping of \"buildingCondition\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c20d7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2790084325.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"bulidingConditionMapping\"] = drop_cols[\"buildingCondition\"].map(buildingConditionMapping)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2790084325.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  drop_cols[\"bulidingConditionMapping\"].fillna(0, inplace=True)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\2790084325.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"bulidingConditionMapping\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "buildingConditionMapping = {\n",
    "    \"AS_NEW\": 1,\n",
    "    \"JUST_RENOVATED\": 2,\n",
    "    \"GOOD\": 3,\n",
    "    \"TO_RENOVATE\": 4,\n",
    "    \"TO_BE_DONE_UP\": 5,\n",
    "    \"TO_RESTORE\": 6,\n",
    "}\n",
    "drop_cols[\"bulidingConditionMapping\"] = drop_cols[\"buildingCondition\"].map(buildingConditionMapping)\n",
    "drop_cols[\"bulidingConditionMapping\"].fillna(0, inplace=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fdbbea",
   "metadata": {},
   "source": [
    "Mapping of \"heatingType\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ce579f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\318446622.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"heatingTypeMapping\"] = drop_cols[\"heatingType\"].map(heatingTypeMapping)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\318446622.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  drop_cols[\"heatingTypeMapping\"].fillna(0, inplace=True)\n",
      "C:\\Users\\Administrateur\\AppData\\Local\\Temp\\ipykernel_21024\\318446622.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  drop_cols[\"heatingTypeMapping\"].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "heatingTypeMapping = {\n",
    "    \"NOT_INSTALLED\": 0,\n",
    "    \"SOLAR\": 1,\n",
    "    \"WOOD\": 2,\n",
    "    \"PELET\": 3,\n",
    "    \"GAS\": 4,\n",
    "    \"FUELOIL\": 5,\n",
    "    \"ELECTRIC\": 6,\n",
    "    \"CARBON\": 7,\n",
    "}\n",
    "drop_cols[\"heatingTypeMapping\"] = drop_cols[\"heatingType\"].map(heatingTypeMapping)\n",
    "drop_cols[\"heatingTypeMapping\"].fillna(0, inplace=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0544f5",
   "metadata": {},
   "source": [
    "Drop epcScore (rangy) values (unprecise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954b56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_epcScore_rows_with_two_letters = ['G_C', 'F_D', 'C_A', 'F_C', 'E_C', 'C_B', 'E_D', 'G_F', 'D_C', 'G_E', 'X']\n",
    "drop_cols = drop_cols[~drop_cols['epcScore'].isin(drop_epcScore_rows_with_two_letters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41ba6a1",
   "metadata": {},
   "source": [
    "Fill the epcScore NaN's by the median which is C(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87b66646",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"epcScore\"] = drop_cols[\"epcScore\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653be86",
   "metadata": {},
   "source": [
    "Adding missing values to these (boolean) columns (that only have True values) as False values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5cf202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"hasOffice\"] = drop_cols[\"hasOffice\"].fillna(False)\n",
    "drop_cols[\"hasAirConditioning\"] = drop_cols[\"hasAirConditioning\"].fillna(False)\n",
    "drop_cols[\"hasSwimmingPool\"] = drop_cols[\"hasSwimmingPool\"].fillna(False)\n",
    "drop_cols[\"hasAttic\"] = drop_cols[\"hasAttic\"].fillna(False)\n",
    "drop_cols[\"hasLift\"] = drop_cols[\"hasLift\"].fillna(False)\n",
    "drop_cols[\"hasBasement\"] = drop_cols[\"hasBasement\"].fillna(False)\n",
    "drop_cols[\"hasFireplace\"] = drop_cols[\"hasFireplace\"].fillna(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a9a885",
   "metadata": {},
   "source": [
    "Remove columns with more than 4 facade and fill mean value that is (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5731c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"facedeCount\"] = drop_cols[\"facedeCount\"].fillna(2) \n",
    "drop_cols = drop_cols[drop_cols['facedeCount'] < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac6ab4c",
   "metadata": {},
   "source": [
    "Delete columns with more 10 parkingCountIndoor and fill 0 for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e96b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"parkingCountIndoor\"] = drop_cols[\"parkingCountIndoor\"].fillna(0) \n",
    "drop_cols = drop_cols[drop_cols['parkingCountIndoor'] < 11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e4773",
   "metadata": {},
   "source": [
    "Fillna missing \"toiletCount\" values with the median of their respective \"type-subtype\" group (appart/house/...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4100f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols[\"toiletCount\"] = drop_cols.groupby(\"type_subtype\")[\"toiletCount\"].transform(lambda x: x.fillna(x.median())) # Replace missing values with median value based on type-subtype group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
